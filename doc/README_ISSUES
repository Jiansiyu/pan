Comments by R. Holmes, 22 May 2002
----------------------------------

(1) I have made some changes in which code that used to exit on a serious
error now just prints a message and passes back a failure status.
This required changing some method types from void to Int_t in TaRun
and TaAnalysisManager, so the error could be propagated up the calling
chain.  

Finally, main.cc was changed to look for these errors and return 1
when found -- likewise macro/run.macro.

This program of changes is incomplete, in that there are still places
where Pan exits rather than passing errors upward; in addition, there
are some routines that are defined as Int_t but always return 0
because I haven't worked on getting status returns into its called
routines.

The goal is to have no exits anywhere in the code.  Turning on
exception handling would presumably make this easier but would slow
things down, so we'll see if we can do it without using exceptions.

(2) There are a couple of things I've noticed in TaAsciiDB which I think
should be addressed.

One is, if one calls GetPedestal before Load has been called, the
value returned is zero (which I guess is OK) but no error message is
printed, and also GetPedestal always returns zero from then on, even
*after* Load has been called.  Here and probably elsewhere, if one
attempts to access the database without first having Loaded it, there
should be an error message -- and it shouldn't break the database!

The other, which I think is related, has to do with the fact that I've
been trying to see what changes are needed in order to run analysis
twice in the same interactive session.  I've already made some changes
to allow this, but it appears Load can't be called twice successfully
-- or some such thing having to do with the database.  The point is
that the user should be able to do:

  % pan
  root [0] .x macro/run.macro
  (enter run number, get analysis)
  root [1] .x macro/run.macro
  (enter run number, get analysis)

with the second analysis (as well as the first) being correct.  Yes,
we did abandon the idea of analyzing multiple runs to get combined
results, and command-line pan doesn't handle more than one run per
invocation; but as long as the interactive version allows macros like
run, it should handle them correctly every time.  Right now, when I
try this with my modified code (which I'll check in shortly), the
second run.macro fails to correctly load the database.

It's unfortunate that correct behavior doesn't happen without some
effort -- that, as written, the first run always pollutes things for
subsequent runs unless we explicitly clean up.  The problems I've
fixed have to do with static class members -- for instance, in
TaPairFromPair there's a list of unpaired events which is static,
because at any time it ought to be the same for all existing
pairs... except that when a new run starts, its pairs ought to have
their own list of unpaired events. I've made a RunInit method for
VaPair, which wipes the list -- this involves an assumption that one
will never have around pairs from two different runs.  That's a valid
assumption, I guess.  Anyway, initialization problems like these need
to be looked at.

I don't know if the database problem is similar or not.  I don't know
the class well enough to fix it myself.


Comments by R. Holmes, 16 Apr 2002
----------------------------------

I tried to put in deletes for everything we new in TaRun.cc.  But
there's some weirdness if I try to delete fEvtree.  If I have this
code in Uncreate():

  delete fEvtree;
  delete fCoda;
  delete fEvent;
  delete fDataBase;
  delete fDevices;
  delete fCutList;
  delete fESliceStats;
  delete fERunStats;
  delete fPSliceStats;
  delete fPRunStats;

then it hangs in delete fEvent.  If I comment out delete fEvent then
it hangs in delete fDataBase (I think, or perhaps one of the later
deletes).  But if I comment out delete fEvtree there's no hang.  I
have the feeling I've seen behavior like this before -- thought maybe
it was because I was trying to delete the same allocation twice, but
I've looked into it and I don't think I am.  Strange.

For now, I comment out delete fEvtree.

TaAsciiDB needs fixes to delete its allocations.


Comments by R. Michaels, 6 Apr 2002
-----------------------------------

Studied profiles and effect of gcc optimization level.  Optimization
can lead an approx 10% increase in speed, not more.  Leave the 
default at level 1 as a compromise between speed of compilation
and speed of code.  

Profiled optimized code shows that 42% of the "visible" time is
spent in TaEvent deep copy.  However, the visible time (i.e. cumulative
time reported by gprof) is only 15% of the total; therefore the deep
copy appears to be 6% of the total.  This is consistent with the
observation that by adjusting MAXKEYS in TaEvent, which adjusts the
size of the deep copy and calibrates its influence on the speed,
the deep copy costs about 6% of cpu time.  Unfortunately, when we
profile without optimization, while the total speed doesn't change
much (10% level), the distribution becomes inconsistent with the
above pattern.  The conclusions for now is that we do not know from
gprof what the main bottlenecks are.

See /doc/prof_opt.dat  and  /doc/prof_noopt.dat


Comments by R. Michaels, 5 Apr 2002
-----------------------------------

As we all know, "pan" was horribly slow.  There appear to have
been three main culprits:

  1. Use of string keys in map<string, *> is slow due to
     log(N) lookup time.  hash_map was ~4 times faster, but
     random access of a static array can be ~100 times faster.

  2. TaEvent contained a plethora of data that needed to be
     copied each time an event was added to a queue.  This
     was unecessary because much of this data never changed.

  3. Thousands of calls from Cut related classes, on average
     per event.  I don't know why.

In this release, I have fixed #1 and #2 (see ChangeLog for details),
and at present "pan" runs at 680 Hz on an 800 MHz PC with local I/O.
This is still a bit slower than "apar" but would be acceptable for
feedback at 30 Hz.  I did not fix #3 yet and leave it to Rich.

I noticed that "gprof" cumulative time falls far short of the
cpu time measured with other methods with or without -pg compile
option (e.g. the method of "time pan -f file").  Some of this 
shortfall is due to ROOT not being compiled with -pg.  Also noticed
that the profile distribution depends on g++ optimization, which is 
reasonable, but it indicates we may benefit from learning more about
g++ optimization.

At present there are still some warnings when compiling and
running the code.  I'm too burned out to fix them now; but they
seem harmless.  However, one thing deserving attention is that
BPM10 x,y differences are very different from the previous version
of "pan".  Actually I think the present version makes sense, but
until the difference is understood, I'm nervous.  Strangely, these 
are the only quantities affected.  All other results (asymmetries, 
differences, root tree values, etc), look identical to previuos
version results.


Comments by R. Holmes, 13 March 2002
---------------------------------

I've changed the code whose intent is to prevent Pan from trying to
compute and print statistics on things like the helicity bit, which
gives errors since the distribution's width is zero.  It's still a
kludge; Pan still accumulates sums for all quantities, but computes
averages and widths and prints them only for quantities whose
description doesn't start with "Left" or "Right".  I'm open to
suggestions of a better way to handle this, which might involve some
major changes to the way results are stored in pairs.

The present code attempts to compute and store in the tree differences
and asymmetries for all pairs, even if they fail cuts.  This is in
keeping with our philosophy of putting everything in the tree and
letting the user decide what's useful (based on cut markers etc.) but
it does give rise to error messages when beam is off and the
denominator of an asymmetry ends up being zero.

I've changed the cuts code so that it multiplies the cut extensions
from the database by the oversample factor; that means the extensions
in the database should be regarded as a number of helicity windows,
not a number of events.  At present these are labelled "evlo" and
"evhi" in the database, and are retrieved by routines with names like
GetEvLo().  We probably should change these names since the "ev" part
is no longer appropriate.


Comments by A. Vacheret, March, 2002
----------------------------------
  
The code uses 32 Mbytes memory at present, I think this is because we have the pair analysis loop
working now. No evident memory leak during a run but Pan is a kind of slow compared to apar. 

Feedback are working but not the cuts yet. With cuts and pedestal calibration, it should 
work like apar.

Statisitics shows error during calculation, didn't take the time to look at this carefully

Will put the type of analysis in the root file name. Also the time parameter for the feedback should be
in the database to be able to change the lenght of a feedback minirun.




Comments by R. Michaels, Feb, 2002
----------------------------------

Several of the problems mentioned below were addressed,
see ChangeLog.

Still some compiler warnings, and you may get in trouble
if you don't 'make clean' before 'make'.

Do we need to distinguish between 'run type' and 'analysis
type' in the database ?  For now I let this distinction exist
and have awkwardly e.g. runtype = anatype = BEAM

