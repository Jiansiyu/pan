Comments by R. Michaels, 6 Apr 2002
-----------------------------------

Studied profiles and effect of gcc optimization level.  Optimization
can lead an approx 10% increase in speed, not more.  Leave the 
default at level 1 as a compromise between speed of compilation
and speed of code.  

Profiled optimized code shows that 42% of the "visible" time is
spent in TaEvent deep copy.  However, the visible time (i.e. cumulative
time reported by gprof) is only 15% of the total; therefore the deep
copy appears to be 6% of the total.  This is consistent with the
observation that by adjusting MAXKEYS in TaEvent, which adjusts the
size of the deep copy and calibrates its influence on the speed,
the deep copy costs about 6% of cpu time.  Unfortunately, when we
profile without optimization, while the total speed doesn't change
much (10% level), the distribution becomes inconsistent with the
above pattern.  The conclusions for now is that we do not know from
gprof what the main bottlenecks are.

See /doc/prof_opt.dat  and  /doc/prof_noopt.dat


Comments by R. Michaels, 5 Apr 2002
-----------------------------------

As we all know, "pan" was horribly slow.  There appear to have
been three main culprits:

  1. Use of string keys in map<string, *> is slow due to
     log(N) lookup time.  hash_map was ~4 times faster, but
     random access of a static array can be ~100 times faster.

  2. TaEvent contained a plethora of data that needed to be
     copied each time an event was added to a queue.  This
     was unecessary because much of this data never changed.

  3. Thousands of calls from Cut related classes, on average
     per event.  I don't know why.

In this release, I have fixed #1 and #2 (see ChangeLog for details),
and at present "pan" runs at 680 Hz on an 800 MHz PC with local I/O.
This is still a bit slower than "apar" but would be acceptable for
feedback at 30 Hz.  I did not fix #3 yet and leave it to Rich.

I noticed that "gprof" cumulative time falls far short of the
cpu time measured with other methods with or without -pg compile
option (e.g. the method of "time pan -f file").  Some of this 
shortfall is due to ROOT not being compiled with -pg.  Also noticed
that the profile distribution depends on g++ optimization, which is 
reasonable, but it indicates we may benefit from learning more about
g++ optimization.

At present there are still some warnings when compiling and
running the code.  I'm too burned out to fix them now; but they
seem harmless.  However, one thing deserving attention is that
BPM10 x,y differences are very different from the previous version
of "pan".  Actually I think the present version makes sense, but
until the difference is understood, I'm nervous.  Strangely, these 
are the only quantities affected.  All other results (asymmetries, 
differences, root tree values, etc), look identical to previuos
version results.


Comments by R. Holmes, 13 March 2002
---------------------------------

I've changed the code whose intent is to prevent Pan from trying to
compute and print statistics on things like the helicity bit, which
gives errors since the distribution's width is zero.  It's still a
kludge; Pan still accumulates sums for all quantities, but computes
averages and widths and prints them only for quantities whose
description doesn't start with "Left" or "Right".  I'm open to
suggestions of a better way to handle this, which might involve some
major changes to the way results are stored in pairs.

The present code attempts to compute and store in the tree differences
and asymmetries for all pairs, even if they fail cuts.  This is in
keeping with our philosophy of putting everything in the tree and
letting the user decide what's useful (based on cut markers etc.) but
it does give rise to error messages when beam is off and the
denominator of an asymmetry ends up being zero.

I've changed the cuts code so that it multiplies the cut extensions
from the database by the oversample factor; that means the extensions
in the database should be regarded as a number of helicity windows,
not a number of events.  At present these are labelled "evlo" and
"evhi" in the database, and are retrieved by routines with names like
GetEvLo().  We probably should change these names since the "ev" part
is no longer appropriate.


Comments by R. Holmes, March 2002
---------------------------------

Compiler warnings at present include:

  TaFdbkAna.hh: In method `TaFdbkAna::TaFdbkAna()':
  TaFdbkAna.hh:79: warning: member initializers for `Int_t TaFdbkAna::fZsent'
  TaFdbkAna.hh:81: warning:   and `Double_t TaFdbkAna::fQmevFdbk'
  TaFdbkAna.cc:39: warning:   will be re-ordered to match declaration order

(Probably just need to swap ordering of a couple of initializers to
fix this.)

  TaCutList.cc: In method `void TaCutList::Init(const class VaDataBase &)':
  TaCutList.cc:66: warning: comparison between signed and unsigned
  TaCutList.cc:69: warning: conversion from `int' to `enum ECutType'

(First is because VaDataBase::GetNumBadEv() returns Int_t and I'm
comparing to size_t.  I'd prefer it if GetNumBadEv() returned UInt_t.

(Second is because the TaCutInterval constructor takes an ECutType
argument, which I must initialize from an Int_t returned from
VaDataBase::GetCutValues().  Probably just need a cast or something.

  TaEvent.cc: In method `void TaEvent::Decode()':
  TaEvent.cc:158: warning: comparison between signed and unsigned

(fSizeConst is UInt_t and it is being compared to (long)GetEvLength().
Why?  GetEvLength() is a UInt_t too; why cast it to long?)



Comments by A. Vacheret, March, 2002
----------------------------------

Resolved other 'discard const' warnings

In VaAnalysis::RunInI() I set the value of fEHelDequeMax at 1 in case of no helicity delay.
That's why we didn't have the pair tree after a run.

TaEvent private variable FirstPS was set to 1 to respect the source convention. 

See other change in ChangeLog
  
The code uses 32 Mbytes memory at present, I think this is because we have the pair analysis loop
working now. No evident memory leak during a run but Pan is a kind of slow compared to apar. 

Feedback are working but not the cuts yet. With cuts and pedestal calibration, it should 
work like apar.

Statisitics shows error during calculation, didn't take the time to look at this carefully

Will put the type of analysis in the root file name. Also the time parameter for the feedback should be
in the database to be able to change the lenght of a feedback minirun.




commit -m "added analysis choice BEAM or FDBK" TaAnalysisManager.cc
commit -m "added analysis choice BEAM or FDBK" TaAnalysisManager.hh
commit -m "added TaFdbkAna " Makefile
commit -m "added member functions" TaRun.cc
commit -m "added member functions" TaRun.hh
commit -m "added some test for asym debug and other" VaAnalysis.cc
commit -m "added some test for asym debug and other" VaAnalysis.hh
commit -m "fixed discard const and bug" TaEvent.cc 
commit -m "fixed discard const and bug" TaEvent.hh
commit -m "fixed discard const" TaADC.cc 
commit -m "fixed conventions" TaPairFromPair.cc
commit -m "fixed discard const" VaDevice.cc
commit -m "fixed conventions and add function for cut test" VaPair.cc
commit -m "fixed conventions and add function for cut test" VaPair.hh
commit -m "new feedback class" TaFdbkAna.hh
commit -m "new feedback class" TaFdbkAna.cc
commit -m "add <math.h>" TaStatistics.hh 



Comments by R. Michaels, Feb, 2002
----------------------------------

Several of the problems mentioned below were addressed,
see ChangeLog.

Still some compiler warnings, and you may get in trouble
if you don't 'make clean' before 'make'.

Do we need to distinguish between 'run type' and 'analysis
type' in the database ?  For now I let this distinction exist
and have awkwardly e.g. runtype = anatype = BEAM

Present status:  I think the event data and database makes
sense now, but not all is well with the helicity code. (It
could be a symptom of problem with the decoding but I doubt 
it.)  There are helicity errors, and no sensible statistic
results.  The ROOT output, however, looks somewhat reasonable.

The code uses 16.6 Mbytes memory at present, and this remains
stable.  One should check it by running 'top' during execution.
There was a memory leak in VaAnalysis::PreProcessEvt() when
the helicity delay was zero.  See my temporary dirty fix.



Comments by R. Holmes, Dec 21, 2001
------------------------------------

VaDataBase.hh had "void DataMapReStart()" which was never defined.
TaAsciiDatabase had the same and defined it.  That was OK with the
compiler, I guess, but not with rootcint.  I have changed it to
"virtual void DataMapReStart()=0" in VaDataBase.hh.

============================================================

I changed the name of TaEvent::Check to CheckEvent, because rootcint
uses a header file, TError.h, that defines Check as a macro.  Which is
really stupid programming on their part, of course.

============================================================

User friendliness needs to improve.  For instance:

  Analysis fails if TIR is not defined in datamap, yet no check is
  made for this.  Analyzer should exit on first event with a message
  to the effect "TIR must be defined in datamap.".

  Note that at least some of the problems currently seen seem to be
  related to problems with the database file; for example, it
  complains about "csr" being used for multiple devices.  I modified
  the error message to make it a little more informative.  Since users
  can in principle screw up the database text files, we MUST make all
  database related error messages as informative as possible to users.

  THaCodaFile::staterr() still aborts the process if the CODA file is
  not found, which is very unfriendly behavior when running
  interactively. 

============================================================

Warnings:
TaADC.cc: In method `void TaADC::Init(const class VaDataBase &)':
TaADC.cc:45: warning: assignment to `int' from `Double_t'

VaDevice.cc: In method `Double_t VaDevice::GetData(const class string &) const':
VaDevice.cc:70: warning: passing `const map<basic_string<char,string_char_traits<char>,__default_alloc_template<true,0> >,double,less<basic_string<char,string_char_traits<char>,__default_alloc_template<true,0> > >,__default_alloc_template<true,0> >' as `this' argument of `Double_t & map<basic_string<char,string_char_traits<char>,__default_alloc_template<true,0> >,double,less<basic_string<char,string_char_traits<char>,__default_alloc_template<true,0> > >,__default_alloc_template<true,0> >::operator []<string, Double_t, less<basic_string<char,string_char_traits<char>,__default_alloc_template<true,0> > >, alloc>(const class string &)' discards const

VaDevice.cc: In method `Double_t VaDevice::GetData(const Int_t &) const':
VaDevice.cc:83: warning: passing `const map<basic_string<char,string_char_traits<char>,__default_alloc_template<true,0> >,double,less<basic_string<char,string_char_traits<char>,__default_alloc_template<true,0> > >,__default_alloc_template<true,0> >' as `this' argument of `Double_t & map<basic_string<char,string_char_traits<char>,__default_alloc_template<true,0> >,double,less<basic_string<char,string_char_traits<char>,__default_alloc_template<true,0> > >,__default_alloc_template<true,0> >::operator []<string, Double_t, less<basic_string<char,string_char_traits<char>,__default_alloc_template<true,0> > >, alloc>(const class string &)' discards const

VaDevice.cc: In method `void VaDevice::FindHeaders(const class TaEvent &)':
VaDevice.cc:142: warning: comparison between signed and unsigned
VaDevice.cc:149: warning: comparison between signed and unsigned

============================================================








