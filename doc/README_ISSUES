Ignore this line

Comments by R. Michaels, Oct 21, 2002
-------------------------------------

The Mysql Perl script must still be developed.  The deadline
is Christmas 2002.  We will make the start-of-run write automatic
database files, as well as automatically update the Mysql database.
Some of the variables must be retrieved from the "Green Monstor"
(our control software for setting up VME parameters).

We probably should delete the entire ./pandb directory tree,
or substantially reduce it.  I think the only useful thing 
there now is the perl script. (?)

When you "Put()" data to database, the output file is in a funny
order because STL map reshuffles things.  Not a big deal.

Comments by A. Vacheret, 25 Sept 2002
----------------------------------

1) A minor thing : right now in TaFileName there is by default the 
path for the coda file which start with a "./"
so if you have your coda file in another directory you get for example
.//avacheret/HAPPEX2/CODA_RUNS/parity02_1302.dat so you need to remove this "./"
by hand in your version of TaFileName.cc to let pan recognize the correct path. 

2) I don't know if it make sense to do feedback only on a PZT direction
X or Y but the new code will be easy to change if this is important to test.
Also almost everything is there to revive the PITA feedback in case we need it.
  
3) to reply Rich comment, as it is mentionned in the ChangeLog,
the feedback monitor could be easily changed in the control.db
file. 

Comments by R. Holmes, 20 Aug 2002
----------------------------------

(1) In places we have various devices hard-coded into Pan.  For
instance, BCM1 is used for beam cuts and for feedback (and I'm working
on a mod to VaAnalysis that provides for normalized asymmetries, again
using BCM1), BPM4B is used for position feedback.  I'd like to be able
to select these in the database instead.  Probably it's best to be
able to select the feedback BCM separately from the beam cuts and
normalization BCM (or even all three separately, though that might be
over the top).  Comments?  Bob, could you put this into the database
class?
  
(2) In TaAsciiDB there's a Bool_t data member called didinit which
seemingly is being used by different methods to mean different things.
Load(runnumber) sets didinit just before returning, and routines like
GetDacNoise(...), GetAdcPed(...), and GetScalPed(...) check it,
apparently to find out if the database has been loaded or not.  But
InitDB() also sets it, and LoadTable(...) and InitDataMap() apparently
check it to find out if the database has been initialized or not.
(These are called by Load(), so they certainly can't be checking to
see if it's loaded or not.)  As far as I know this doesn't cause any
actual misbehavior, but I see it as a source of potential confusion.

In particular, any routine that needs the database initialized doesn't
need to complain and return an error if didinit is false; it could just
call InitDB().  But if it needs the database loaded, it can't call
Load(runnumber) because it doesn't know the run number.  I think I know
which methods need which prerequisite, but due to this "overload" of
didinit I'm not 100 percent certain. (Actually
TaAsciiDB::Load(runnumber) doesn't need the run number any more, because
all it used it for was to construct the database file name, and that's
now handled by the TaFileName methods; but TaMysql::Load(runnumber)
presumably does need the run number.)

(3) Bug in TaAsciiDB (and in TaMysql): The following statement is
needed in DataMapReStart:

    firstiter = kTRUE;

Otherwise when one tries to cycle through the datamap a second or later
time, one does not get the first datamap entry, which happens to be the
first ADC defined.

I won't bother committing this since I know Bob is working on these
classes, probably putting DataMapReStart into VaDatabase, and it might
as well be committed with the rest of his changes.  You can patch your
copy for now and get it working.


Comments by R. Holmes, 7 Aug 2002
----------------------------------

Quadsynch needs to be loaded in TaEvent::Load once that signal exists
in hardware.


Comments by R. Holmes, 26 Jul 2002
----------------------------------

With the new standardized file names, the macros that expect to find
pan_%d.root will break.  The quick and dirty fix will be to change
these to parity02_%d.root, but it may be worthwhile to do something
more elegant.


Comments by R. Holmes, 23 Jul 2002
----------------------------------

TaMysql is even more broken, because it needs a GetCutNames
definition. 

(Note, though, that GetCutNumber is defined in VaDataBase in terms of
other database methods -- so that, at least, should work with the SQL
database.) 


Comments by R. Michaels, 23 July 2002
-------------------------------------

After the round of changes to incorporate scalers as alternatives
to ADCs (see the ChangeLog for details), we have the following issues
to fix:

1. TaMysql is broken.  To the extent possible, both it and TaAsciiDB
   classes should use inheritance to minimize the pain of changing the code.
   (That's what C++ is supposed to do !!)

2. scaler calibration needs to be done correctly in TaEvent::Decode

3. Perl script to generate DevTypes.hh is desirable.


Comments by R. Holmes, 16 Apr 2002
----------------------------------

I tried to put in deletes for everything we new in TaRun.cc.  But
there's some weirdness if I try to delete fEvtree.  If I have this
code in Uncreate():

  delete fEvtree;
  delete fCoda;
  delete fEvent;
  delete fDataBase;
  delete fDevices;
  delete fCutList;
  delete fESliceStats;
  delete fERunStats;
  delete fPSliceStats;
  delete fPRunStats;

then it hangs in delete fEvent.  If I comment out delete fEvent then
it hangs in delete fDataBase (I think, or perhaps one of the later
deletes).  But if I comment out delete fEvtree there's no hang.  I
have the feeling I've seen behavior like this before -- thought maybe
it was because I was trying to delete the same allocation twice, but
I've looked into it and I don't think I am.  Strange.

For now, I comment out delete fEvtree.

TaAsciiDB needs fixes to delete its allocations.


Comments by R. Michaels, 6 Apr 2002
-----------------------------------

Studied profiles and effect of gcc optimization level.  Optimization
can lead an approx 10% increase in speed, not more.  Leave the 
default at level 1 as a compromise between speed of compilation
and speed of code.  

Profiled optimized code shows that 42% of the "visible" time is
spent in TaEvent deep copy.  However, the visible time (i.e. cumulative
time reported by gprof) is only 15% of the total; therefore the deep
copy appears to be 6% of the total.  This is consistent with the
observation that by adjusting MAXKEYS in TaEvent, which adjusts the
size of the deep copy and calibrates its influence on the speed,
the deep copy costs about 6% of cpu time.  Unfortunately, when we
profile without optimization, while the total speed doesn't change
much (10% level), the distribution becomes inconsistent with the
above pattern.  The conclusions for now is that we do not know from
gprof what the main bottlenecks are.

See /doc/prof_opt.dat  and  /doc/prof_noopt.dat


Comments by R. Michaels, 5 Apr 2002
-----------------------------------

As we all know, "pan" was horribly slow.  There appear to have
been three main culprits:

  1. Use of string keys in map<string, *> is slow due to
     log(N) lookup time.  hash_map was ~4 times faster, but
     random access of a static array can be ~100 times faster.

  2. TaEvent contained a plethora of data that needed to be
     copied each time an event was added to a queue.  This
     was unecessary because much of this data never changed.

  3. Thousands of calls from Cut related classes, on average
     per event.  I don't know why.

In this release, I have fixed #1 and #2 (see ChangeLog for details),
and at present "pan" runs at 680 Hz on an 800 MHz PC with local I/O.
This is still a bit slower than "apar" but would be acceptable for
feedback at 30 Hz.  I did not fix #3 yet and leave it to Rich.

I noticed that "gprof" cumulative time falls far short of the
cpu time measured with other methods with or without -pg compile
option (e.g. the method of "time pan -f file").  Some of this 
shortfall is due to ROOT not being compiled with -pg.  Also noticed
that the profile distribution depends on g++ optimization, which is 
reasonable, but it indicates we may benefit from learning more about
g++ optimization.

At present there are still some warnings when compiling and
running the code.  I'm too burned out to fix them now; but they
seem harmless.  However, one thing deserving attention is that
BPM10 x,y differences are very different from the previous version
of "pan".  Actually I think the present version makes sense, but
until the difference is understood, I'm nervous.  Strangely, these 
are the only quantities affected.  All other results (asymmetries, 
differences, root tree values, etc), look identical to previuos
version results.


Comments by A. Vacheret, March, 2002
----------------------------------
  
The code uses 32 Mbytes memory at present, I think this is because we have the pair analysis loop
working now. No evident memory leak during a run but Pan is a kind of slow compared to apar. 

Feedback are working but not the cuts yet. With cuts and pedestal calibration, it should 
work like apar.

Statisitics shows error during calculation, didn't take the time to look at this carefully

Will put the type of analysis in the root file name. Also the time parameter for the feedback should be
in the database to be able to change the lenght of a feedback minirun.




Comments by R. Michaels, Feb, 2002
----------------------------------

Several of the problems mentioned below were addressed,
see ChangeLog.

Still some compiler warnings, and you may get in trouble
if you don't 'make clean' before 'make'.

Do we need to distinguish between 'run type' and 'analysis
type' in the database ?  For now I let this distinction exist
and have awkwardly e.g. runtype = anatype = BEAM

